---
layout:     post
title:      "「机器学习」 生成对抗网络"
subtitle:   "Generative Adversarial Networks"
date:       2023-02-19 12:00:00
author:     "Azaan"
header-img: "img/post-bg-machine-learning.jpg"
katex: true
tags:
    - 机器学习
---



生成对抗网络（Generative Adversarial Network，GAN）是一个生成模型，它学习所提供的样本，并可以生成不同于训练样本的新结果。其基本思想很简单，由一个判别器和一个生成器组成。主网络通过将随机噪声映射到输出数据空间来生成样本，如果判别器不能区分生成的样本和真实的样本，那么可以说生成的样本是成功的；如果判别器可以判别出差异，那么这就提供了一个可以反馈的训练信号，以提高样本的质量。GAN在图像领域取得了最大的成功，在这里可以生成与真实图片几乎没有区别的样本。

# GAN的基本思想

设训练数据为 $\{ \mathbf{x_i} \}$，我们的目的是生成新的样本 $\{\mathbf{x_i^*} \}$，使得新样本和原始数据无法分辨。一个新样本 $\mathbf{x}_{j}^{*}$ 的生成过程大致为，首先从简单的基本分布（如标准正态分布）中选择一个隐变量（latent variable）$\mathbf{z}_j$ ，然后放到网络中得到 $\mathbf{x^*=g[z_j,\theta]}$ ，其中 $\mathbf{\theta}$ 是网络参数。这个网络即生成器（generator），网络学习的目标是找到最好的 $\mathbf{\theta}$ ，使得生成的样本看起来和真实原始数据非常相似。

GAN对相似度的评价方式是，能否将生成的结果和原始真值区分开来。为了这个目的，我们引入第二个网络 $f[\bullet , \phi]$ ，此网络即判别器（discriminator），其中 $\phi$ 为网络参数。这个网络的目标是将输入分类为是一个真实样本还是生成结果。如果我们已经无法区分，那么我们可以说生成的样本是成功的。如果仍然可以区分，那么判别器将会提供一个信号来提高生成效果。

![](https://azaan-zheng.github.io/img/machine-learning/20230219/1.jpg)

如图所示，我们以一维训练集 $\{x_i\}$ 开始，一个batch中含有十个样例（图中的蓝色箭头），为了生成一个batch的新样本，我们使用如下的简单生成方式：


$$
x_j^*=g[z_j,\theta]=z_j + \theta
$$


这里隐变量 $\{z_j\}$ 是从标准正态分布中选取的，参数 $\theta$ 即沿x轴方向进行平移。当初始化$\theta = 3.0$ 时，生成的样本（橙色箭头）位于真实样本的左部，判别器被训练为将生成的样本和真实样本区分开来， 这里的 sigmoid 曲线即表示了这个样本是否为真实样本的概率。在训练过程中，生成器参数 $\theta$ 得到反馈并且自增，以增加样本被分类为真实样本的概率。

我们交替更新判别器和生成器。上图中的b）和c）展示了两个迭代过程。将样本进行区分变得越来越困难，因此使 $\theta$ 增加的动力变得越来越弱（如图 sigmoid 函数变得更加平坦）。在最后，已经无法分辨二者，我们可以丢下判别器，并得到一个可以乱真的生成器。

### 损失函数

我们现在定义一个损失函数，来更加精确地训练GAN。我们用 $f[\mathbf{x,\phi}]$ 来表示判别器，它以 $\mathbf{x}$ 作为输入，参数为 $\phi$ ，并且返回输入为真的概率。这是一个二元分类任务，我们引入二元交叉熵损失函数：


$$
\hat{\phi} = \mathop{\arg\min}_{\phi} \left[ \sum_i -(1-y_i)log\left[ 1- sig[f[\mathbf{x,\phi}]] \right] -y_i log \left[ sig[f[\mathbf{x,\phi}]]\right] \right]
$$



这里 $y_i \in \{0,1 \}$ 是判别的结果，$sig[\bullet]$ 是logistic sigmoid函数，如图所示，我们假定真实样本 $\mathbf{x}$ 对应 $y=1$，生成样本 $\mathbf{x}^*$ 对应 $y=0$，因此有：


$$
\hat{\phi} = \mathop{\arg \min}_{\phi} \left[ \sum_j -log\left[ 1-sig[f[\mathbf{x_j^*,\phi}]]\right] - \sum_i log\left[ sig[f[\mathbf{x_i,\phi}]]\right] \right]
$$


其中 $i$ 和 $j$ 对应真实样本和生成样本的索引。

现在我们将生成器的定义替换为 $\mathbf{x_j^*=g[z_j,\theta]}$ 并且我们希望找到 $\mathbf{\theta}$ 使得损失结果更大（因为我们希望生成的样本被错误分类）：


$$
\hat{\phi},\hat{\theta} = \mathop{\arg \max}_{\theta} 
\left[ 
\mathop{\min}_{\phi}
\left[
\sum_j - log\left[1-sig[f[\mathbf{g[z_j,\theta],\phi}]] \right]
-\sum_i log\left[ sig[f[\mathbf{x_i,\phi}]] \right]
\right]
\right]
$$


### 训练GAN

GAN训练被描述为 $minimax\ \ game$，生成器试图找到欺骗判别器的新方法，判别器反过来寻找新方法来区分生成的样本和真实示例。理论上来说，解决方案是一个是一个纳什均衡——优化算法搜索一个位置，该位置同时是一个函数的最小值和另一个函数的最大值。如果训练如期进行，那么收敛后 $\mathbf{g[z,\theta]}$ 将从与训练数据相同的分布中提取，然后 $sig[f[\mathbf {\bullet,\phi}]]$ 将会接近随机（即概率0.5）。

为了训练GAN，我们可以将前式分解为两个损失函数：


$$
\begin{array}{l}
L[\phi] = \sum\limits_{j} -log\left[1-sig[f[\mathbf{g[z_j,\theta],\phi}]] \right] - \sum\limits_i log\left[ sig[f[\mathbf{x_i,\phi}]]\right]
\\
L[\theta] = \sum\limits_j log\left[ 1-sig[f[\mathbf{g[z_j,\theta],\phi}]]\right]
\end{array}
$$


在第二个函数中，我们取负并且舍弃无关项，使得我们的损失函数目标都是最小化。最小化第一个函数来训练判别器，最小化第二个函数来训练生成器。

![](https://azaan-zheng.github.io/img/machine-learning/20230219/2.jpg)



如上图，在每一步，我们都从基本分布中选择一个bacth的隐变量 $\mathbf{z}_j$ 并将其送入生成器，得到生成样本 $\mathbf{x_j^*=g[z_j,\theta]}$ 。然后我们选择一个batch的真实样本 $\mathbf{x}_i$ ，得到这两个batch，我们可以对每个损失函数执行一个或者多个梯度下降步骤。

### 深度卷积GAN

![](https://azaan-zheng.github.io/img/machine-learning/20230219/3.jpg)

深度卷积对抗神经网络（deep convolutional GAN，DCGAN），是一个用于生成图片的较早的GAN结构。生成器的输入是一个从标准分布中选取的100维的隐变量 $\mathbf{z}$ ，之后使用线性映射将其映射到一个具有1024个通道的 $4\times4$ 的空间表示。后面是4个卷积层，每个卷积层都使用分数步长，使得分辨率翻倍（即步长为0.5的卷积）。在最后一层中，这个 $64\times 64\times 3$ 的信号通过一个 arctan 函数来生成一个分布在 $[-1,1]$ 的图片 $\mathbf{x}^*$ 。

判别器是一个标准卷积神经网络，其最后一个卷积层将大小降低到单通道的 $1\times 1$ 大小。这个数字后面通过一个 sigmoid 函数来得到输出的概率。在训练之后，判别器就被丢弃，我们只需要从基本分布中选择隐变量通过生成器生成结果。

###  训练GAN的困难

GAN很难训练，为了让DCGAN可靠地训练，一般的措施如下：

- 使用跨步卷积进行上采样和下采样；
- 在生成器和判别器中，除了最后一层和第一层，都分别使用 BatchNorm；
- 在判别器中使用Leaky ReLU激活函数；
- 使用Adam优化器，但动量系数比平时低； 

一个常见的失败模式是生成器会生成似是而非的样本，但是仅限于训练数据的子集（例如对于人脸，它可能永远不会生成有胡须的人脸），这称为模式丢弃（mode dropping）。这种现象的一个极端版本是生成器完全忽略输入变量 $\mathbf{z}$ 并将所有样本折叠到一个或几个点，这被称为模式崩溃（mode collapse）。

# 提高稳定性

要理解为什么GAN难以训练，有必要准确理解损失函数的含义。

### 损失函数分析

我们先来介绍KL散度（Kullback-Leibler divergence），它常常用来衡量两个概率分布之间的距离，其定义如下所示：


$$
D_{KL} \left[ p(x)||q(x)\right] = \int p(x) \log \left[ \frac{p(x)}{q(x)} \right]dx
$$


这个距离总是大于等于零，我们可以利用 $-\log \left[ y \right] \ge 1-y$ 来证明如下：


$$
\begin{array}{l}
D_{KL} \left[ p(x)||q(x) \right] & = & \int p(x) \log \left[ \frac{p(x)}{q(x)} \right]dx \\
& = & -\int p(x) \log\left[ \frac{q(x)}{p(x)} \right] dx \\
& \ge & \int p(x) \left( 1- \frac{q(x)}{p(x)} \right)dx \\
& = & \int p(x)-q(x) dx \\
& = & 1-1=0
\end{array}
$$


当 $q(x)$ 为 0 而 $p(x)$ 不为 0 的时候，KL散度将为无穷，这将使得它作为一个距离度量相当不稳定。而且KL散度还有一个缺点是它并不是对称的，为此我们引入JS散度（Jensen-Shannon divergence），它是KL散度两个方向的平均：


$$
D_{JS} \left[ p(x)||q(x)  \right] = \frac{1}{2} D_{KL} \left[p(x)||\frac{p(x)+q(x)}{2} \right] + \frac{1}{2} D_{KL} \left[q(x)||\frac{p(x)+q(x)}{2} \right]
$$


我们现在回顾损失函数 $L[\phi]$ ，并分别对 $i,j$ 的损失取平均，我们可以得到损失函数的期望形式：


$$
\begin{array}{l}
L[ \phi] & = & \frac{1}{J} \sum\limits_{j=1}^{J} \left( \log\left[1-sig[f[\mathbf{x_j^*,\phi}]]\right] \right) + \frac{1}{I} \sum\limits_{i=1}^I \left(\log\left[ sig[f[\mathbf{x_i,\phi}]]\right] \right) \\
& \approx & \mathbb{E}_{\mathbf{x}^*} \left[\log\left[1-sig[f[\mathbf{x^*,\phi}]]\right]\right] + \mathbb{E}_{\mathbf{x}^*} \left[\log\left[sig[f[\mathbf{x^*,\phi}]]\right]\right] \\
& = & \int Pr(\mathbf{x}^*) \log \left[1-sig[f[\mathbf{x^*,\phi}]]\right]d\mathbf{x}^* + \int Pr(\mathbf{x}) \log \left[sig[f[\mathbf{x,\phi}]]\right]d\mathbf{x}
\end{array}
$$


其中 $Pr(\mathbf{x^*})$ 是生成样本的概率分布，而 $Pr(\mathbf{x})$ 是真实样本的概率分布。最佳的判别器应当取值如下：


$$
Pr(\mathbf{x}\ \ is \ \ real)=sig[f[\mathbf{x,\phi}]] = \frac{Pr(\mathbf{x})}{Pr(\mathbf{x}^*) + Pr(\mathbf{x})}
$$


即此处样本为真实样本的概率，等价于此处样本为真的分布占总分布的比例。将其带入前面的推导，可以得到：


$$
\begin{array}{l}
L[\phi] &=& \int Pr(\mathbf{x}^*)\log \left[1-sig[f[\mathbf{x^*,\phi}]]\right]d\mathbf{x}^* + \int Pr(\mathbf{x})\log \left[sig[f[\mathbf{x,\phi}]]\right]d\mathbf{x} \\
&=& \int Pr(\mathbf{x}^*) \log\left[1-\frac{Pr(\mathbf{x})}{Pr(\mathbf{x}^*)+Pr(\mathbf{x})} \right]d\mathbf{x}^* + \int Pr(\mathbf{x}) \log\left[\frac{Pr(\mathbf{x})}{Pr(\mathbf{x}^*)+Pr(\mathbf{x})} \right]d\mathbf{x} \\
&=& \int Pr(\mathbf{x}^*) \log\left[\frac{Pr(\mathbf{x}^*)}{Pr(\mathbf{x}^*)+Pr(\mathbf{x})} \right]d\mathbf{x}^* + \int Pr(\mathbf{x}) \log\left[\frac{Pr(\mathbf{x})}{Pr(\mathbf{x}^*)+Pr(\mathbf{x})} \right]d\mathbf{x}
\end{array}
$$


忽略乘法和加法常数，上式等价于 $Pr(\mathbf{x}^*)$ 和 $Pr(\mathbf{x})$ 之间的JS散度：


$$
\begin{array}{l}
D_{JS}\left[Pr(\mathbf{x}^*)||Pr(\mathbf{x}) \right] \\
 =  \frac{1}{2}D_{KL} \left[Pr(\mathbf{x}^*)||\frac{Pr(\mathbf{x}^*)+Pr(\mathbf{x})}{2} \right] + \frac{1}{2}D_{KL} \left[Pr(\mathbf{x})||\frac{Pr(\mathbf{x}^*)+Pr(\mathbf{x})}{2} \right] \\
 =  \frac{1}{2} \int \underbrace{Pr(\mathbf{x}^*)\log \left[\frac{2Pr(\mathbf{x}^*)}{Pr(\mathbf{x}^*) + Pr(\mathbf{x})} \right]}_{quality} + \underbrace{Pr(\mathbf{x})\log \left[\frac{2Pr(\mathbf{x})}{Pr(\mathbf{x}^*) + Pr(\mathbf{x})} \right]}_{coverage} d\mathbf{x}
\end{array}
$$


这里面的第一项表明，如果希望距离变小，在生成样本密度较大的区域（即 $ Pr( \mathbf{x^*} )$ 较高），需要让均值 $(Pr(\mathbf{x^*}) + Pr(\mathbf{x}))/2$ 更高，即它惩罚那些有生成样本却没有真实样本的区域，即提高生成样本的质量（quality）。这里面的第二项表明，如果希望距离变小，在真实样本密度较大的区域（即 $Pr(\mathbf{x})$ 较高），需要让均值 $(Pr(\mathbf{x^*}) + Pr(\mathbf{x}))/2$ 更高，即它惩罚那些有真实样本却没有生成样本的区域，即提高生成样本的覆盖范围（coverage）。

但是我们发现，负责coverage的项，对应 $L[\phi]$ 的第二项，其中并没有生成样本参与，因此它不依赖于生成器。故而生成器并不关心覆盖范围，从而倾向于生成可能示例的子集。
















### 参考文献

1. 《Understanding Deep Learning》Simon J.D. Prince



